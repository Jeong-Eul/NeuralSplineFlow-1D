{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "789f69da",
   "metadata": {},
   "source": [
    "## Neural Spline Flow 1D for estimating distribution of potential outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "351f4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "code_dir = os.path.abspath(os.path.join(os.getcwd(), '.', 'code'))\n",
    "if code_dir not in sys.path:\n",
    "    sys.path.append(code_dir)\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import argparse\n",
    "import pickle\n",
    "import imageio\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from neural_spline_flow1D import NeuralSplineFlow1D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.distributions import Normal\n",
    "from IPython.display import display, Markdown\n",
    "from gif import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556553f2",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe40a379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster ID</th>\n",
       "      <th>Sample Count</th>\n",
       "      <th>Center (prev_output)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3531</td>\n",
       "      <td>33.363160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>700.420938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>527</td>\n",
       "      <td>268.839934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster ID  Sample Count  Center (prev_output)\n",
       "0           0          3531             33.363160\n",
       "1           1           162            700.420938\n",
       "2           2           527            268.839934"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "potential_outcome_df = pd.read_csv('./data/processed_potential_outcome.csv')\n",
    "valid_df = potential_outcome_df[potential_outcome_df['prev_output']>5]\n",
    "\n",
    "del potential_outcome_df\n",
    "\n",
    "# KMeans\n",
    "prev_outputs = valid_df[['prev_output']].copy()\n",
    "\n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init='auto')\n",
    "prev_outputs['cluster'] = kmeans.fit_predict(prev_outputs)\n",
    "\n",
    "cluster_counts = prev_outputs['cluster'].value_counts().sort_index()\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "cluster_summary = pd.DataFrame({\n",
    "    'Cluster ID': cluster_counts.index,\n",
    "    'Sample Count': cluster_counts.values,\n",
    "    'Center (prev_output)': cluster_centers.flatten()\n",
    "})\n",
    "\n",
    "display(cluster_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99a96fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_1d_kde(ssc, device, base_dist, y_original, model, epoch, cluster, treatment):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Normal distribution\n",
    "        z_samples = base_dist.sample((50000,)).to(device)\n",
    "        \n",
    "        # Flow forward\n",
    "        y_vis, _ = model._elementwise_forward(z_samples.unsqueeze(-1))\n",
    "        y_np = y_vis.detach().cpu().squeeze().numpy()  \n",
    "        \n",
    "        inversed = ssc.inverse_transform(y_np.reshape(-1, 1))\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.hist(y_original, bins=30, density=True, alpha=0.3, color='gray', label='Histogram') # 관측 히스토그램\n",
    "        sns.kdeplot(inversed, label=f'P(Y[{treatment}] = y)', color='green')\n",
    "        plt.title(f\"Epoch {epoch}\")\n",
    "        plt.xlabel(\"y\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.legend()\n",
    "        \n",
    "        png_dir = f\"train_plots_Cancer_cluster_{cluster}_treatment_{treatment}\"\n",
    "        \n",
    "        os.makedirs(png_dir, exist_ok=True)\n",
    "        plt.savefig(png_dir + f\"/epoch_{epoch:04d}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b95f5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif_from_train_plots(treatment, cluster, fname: str) -> None:\n",
    "\n",
    "    png_dir = f\"train_plots_Cancer_cluster_{cluster}_treatment_{treatment}/\"\n",
    "    images = []\n",
    "    sort = sorted(os.listdir(png_dir))\n",
    "    for file_name in sort[1::1]:\n",
    "        if file_name.endswith(\".png\"):\n",
    "            file_path = os.path.join(png_dir, file_name)\n",
    "            images.append(imageio.imread(file_path))\n",
    "\n",
    "    imageio.mimsave(\"./code/gifs/\" + fname, images, duration=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088776c6",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5e51aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010: Loss=0.0270 \n",
      "Epoch 020: Loss=0.0207 \n",
      "Epoch 030: Loss=0.0150 \n",
      "Epoch 040: Loss=0.0103 \n",
      "Epoch 050: Loss=0.0075 \n",
      "Epoch 060: Loss=0.0059 \n",
      "Epoch 070: Loss=0.0047 \n",
      "Epoch 080: Loss=0.0038 \n",
      "Epoch 090: Loss=0.0032 \n",
      "Epoch 100: Loss=0.0027 \n",
      "Epoch 110: Loss=0.0023 \n",
      "Epoch 120: Loss=0.0021 \n",
      "Epoch 130: Loss=0.0018 \n",
      "Epoch 140: Loss=0.0016 \n",
      "Epoch 150: Loss=0.0015 \n",
      "Epoch 160: Loss=0.0013 \n",
      "Epoch 170: Loss=0.0012 \n",
      "Epoch 180: Loss=0.0010 \n",
      "Epoch 190: Loss=0.0009 \n",
      "Epoch 200: Loss=0.0007 \n",
      "Epoch 210: Loss=0.0007 \n",
      "Epoch 220: Loss=0.0006 \n",
      "Epoch 230: Loss=0.0005 \n",
      "Epoch 240: Loss=0.0004 \n",
      "Epoch 250: Loss=0.0004 \n",
      "Epoch 260: Loss=0.0003 \n",
      "Epoch 270: Loss=0.0003 \n",
      "Epoch 280: Loss=0.0003 \n",
      "Epoch 290: Loss=0.0002 \n",
      "Epoch 300: Loss=0.0002 \n",
      "Epoch 310: Loss=0.0002 \n",
      "Epoch 320: Loss=0.0002 \n",
      "Epoch 330: Loss=0.0002 \n",
      "Epoch 340: Loss=0.0001 \n",
      "Epoch 350: Loss=0.0001 \n",
      "Epoch 360: Loss=0.0001 \n",
      "Epoch 370: Loss=0.0001 \n",
      "Epoch 380: Loss=0.0001 \n",
      "Epoch 390: Loss=0.0000 \n",
      "Epoch 400: Loss=-0.0000 \n",
      "Epoch 410: Loss=-0.0001 \n",
      "Epoch 420: Loss=-0.0001 \n",
      "Epoch 430: Loss=-0.0001 \n",
      "Epoch 440: Loss=-0.0001 \n",
      "Epoch 450: Loss=-0.0001 \n",
      "Epoch 460: Loss=-0.0001 \n",
      "Epoch 470: Loss=-0.0001 \n",
      "Epoch 480: Loss=-0.0002 \n",
      "Epoch 490: Loss=-0.0002 \n",
      "Epoch 500: Loss=-0.0002 \n",
      "Estimated ∫ p_Y(y) dy ≈ 1.0000\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Choose cluster number you want to analyze\n",
    "cluster_num = 2\n",
    "\n",
    "# Choose treatment number you want to analyze (1: not treated, 2: Chemo, 3: Radio, 4: Both)\n",
    "treatment = 4\n",
    "\n",
    "centroid = cluster_summary[cluster_summary['Cluster ID'] == cluster_num]['Center (prev_output)'].values\n",
    "\n",
    "cluster_data = prev_outputs[prev_outputs['cluster'] == cluster_num]\n",
    "filtered_df = valid_df.loc[cluster_data.index]\n",
    "\n",
    "df = filtered_df.copy()\n",
    "ssc = MinMaxScaler()\n",
    "df[f'y{treatment}_scaled']=ssc.fit_transform(df[f'y{treatment}'].values.reshape(-1, 1))\n",
    "\n",
    "# hyperparameter setting\n",
    "batch_size = len(df)\n",
    "\n",
    "dataset = TensorDataset(torch.tensor(df[f'y{treatment}_scaled'].values).unsqueeze(-1))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "features = 1 # 1 Dimension\n",
    "num_bins = 10\n",
    "epochs = 500\n",
    "\n",
    "model = NeuralSplineFlow1D(features, num_bins).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "base_dist = torch.distributions.Normal(0, 1)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        x_batch = batch[0].to(device).float()   # shape: (batch_size, 1) or (batch_size,)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        z, logdet = model._elementwise_inverse(x_batch) # x -> z_0\n",
    "        logprob = base_dist.log_prob(z).sum(dim=-1)\n",
    "        loss = -(logprob + logdet).mean()\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    N = len(dataloader.dataset)\n",
    "    avg_loss = epoch_loss / N\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:03d}: \"\n",
    "            f\"Loss={avg_loss:.4f} \")\n",
    "\n",
    "    if epoch == 1 or epoch % 1 == 0:\n",
    "        plot_training_1d_kde(ssc, device, base_dist, df[f'y{treatment}'].values, model, epoch, cluster_num, treatment)\n",
    "        \n",
    "    model_path = f'{dataset}_PO_distribution/'\n",
    "        \n",
    "    save_dict = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'scaler': ssc,\n",
    "        'bins': num_bins,\n",
    "        'centroid':centroid,\n",
    "        'features': features\n",
    "    }\n",
    "        \n",
    "sum_probability(model, base_dist, device)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8bfc7b",
   "metadata": {},
   "source": [
    "### Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb9446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<img src=\"./code/gifs/example.gif\" width=\"400\">"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate and display an animation of the training progress.\n",
    "make_gif_from_train_plots(treatment, cluster_num, f'example.gif')\n",
    "display(Markdown('<img src=\"./code/gifs/example.gif\" width=\"400\">'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b4b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
